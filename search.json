[
  {
    "objectID": "team/index.html",
    "href": "team/index.html",
    "title": "Founding Team",
    "section": "",
    "text": "Founding Team\nDave Petrovics  | CEO\n\n\nDave led Stripe’s Developer Platform organization for nearly a decade, overseeing the API, SDKs, developer tools, and internal product infrastructure. He built Stripe’s v2 API and launched numerous developer products at global scale. BSE mechanical & aerospace engineering, Princeton.\n\n\n\n\n\n\nAaron Steele  | President\n\n\nAaron led data, machine learning, and machine learning infrastructure teams at Stripe that developed Rainier and built the real-time production AI systems behind Radar. He also co-founded WRI’s Data Lab as CTO, leading the research engineering teams that launched Global Forest Watch. BA computer science, Berkeley.\n\n\n\n\n\n\nSam Ritchie  | CTO\n\n\nSam has built AI developer tools and large-scale stream processing systems at Twitter, Stripe, and Google X. He created Twitter’s streaming analytics platform, designed ML infrastructure at Stripe, led research tooling at X, and built the Emmy computational physics library. BSE Mechanical & Aerospace engineering, Princeton.\n\n\n\n\n\n\nAndrew Bolton  | Research Scientist\n\n\nAndrew’s research bridges engineering, probabilistic programming and biological computation. He has identified novel visual pathways, uncovered computational principles of zebrafish vision, and applied probabilistic programming techniques to describe visuomotor algorithms. Recently co-invented the SMCNN framework for probabilistic neural computation. PhD Brain and Cognitive Sciences (MIT).\n\n\n\n\n\n\nMatin Ghavami  | Research Scientist\n\n\nMatin bridges programming languages and mathematics of probability. At the MIT Probabilistic Computing Project, he co-developed probabilistic programming systems for 3D scene perception and contributed to inference strategies and languages for probabilistic inference. BA Mathematics and BS EECS, Berkeley; Master Mathematics, Cambridge; PhD student, MIT.\n\n\n\n\n\n\nMcCoy Becker  | Research Scientist\n\n\nMcCoy is the main designer of the probabilistic programming system GenJAX, which in addition to being the primary modeling language of the MIT Probabilistic Computing Project, has been used to extend PPL use for programmable variational inference. McCoy has extensive experience working in industry settings (Charles River Analytics, Beacon Biosignals, Google Research) on machine learning applications using deep learning. PhD student, MIT.\n\n\n\n\n\n\n\n\nScientific Collaborators\nJosh Tenenbaum  | Professor @ MIT\n\n\nJosh is a Professor of Computational Cognitive Science at MIT, Director of Science at the MIT Quest for Intelligence, and a Principal Investigator at CSAIL. His research seeks to reverse-engineer human intelligence by integrating cognitive science, neuroscience, and computer science, with a focus on how humans learn and reason from limited data. A MacArthur Fellow, he earned his PhD from MIT and co-leads the Center for Brains, Minds and Machines.\n\n\n\n\n\n\n\n\nAdvisors\nSam Gershman  | Professor @ Harvard\n\n\nSam is a Professor in the Department of Psychology and Center for Brain Science at Harvard. He serves as associate faculty at the Kempner Institute for the Study of Natural and Artificial Intelligence. His research focuses on computational cognitive neuroscience, aiming to understand how structured knowledge about the environment is acquired and utilized for adaptive behavior. He completed his Ph.D. in Psychology and Neuroscience at Princeton University.\n\n\n\n\n\n\n\n\nTeam Press\n\nMIT News: Smarter Zebrafish Study\nMIT News: Generative AI for Databases\nMIT EECS: Machines That See the World Like Humans Do\nMIT News: Automating Math Decision-Making Under Uncertainty\nMIT News: Cracking the Code Relating Brain and Behavior\nWired: How the Nephew of Computer Science Royalty Remade Twitter"
  },
  {
    "objectID": "contact/index.html",
    "href": "contact/index.html",
    "title": "FrogRocket Labs",
    "section": "",
    "text": "We’d love to hear from you — say hello@frogrocket.ai."
  },
  {
    "objectID": "research/index.html",
    "href": "research/index.html",
    "title": "Papers",
    "section": "",
    "text": "Bayes3D — Uncertainty-Aware 3D Scene Perception with Novel Objects Read the paper ➔\nPresented an uncertainty-aware 3D scene perception system with GPU-accelerated pose tracking and novel object learning, capable of faster than real time 3D object tracking.\n3DP3 — 3D Scene Perception via Probabilistic Programming Read the paper ➔\nPresented 3D scene perception using inverse graphics — probabilistic inference in a structured generative model of objects, scenes, and images — the resulting algorithm produced representations aware of 3D shape, occlusion, and contact structure.\n\n\n\n\nGenSP — Probabilistic Programming with Stochastic Probabilities Read the paper ➔\nPresented the first probabilistic programming language with expressive constructs like marginalization & nested inference, and features like continuous and discrete random variables, and programmable inference.\nGenSQL — PPL for Querying Probabilistic Database Models Read the paper ➔\nBy extending SQL with a few probabilistic primitives, presented a query language for generative models of database tables, illustrating how probabilistic tools can augment and extend conventional software systems.\n\n\n\n\nADEV — Automatic Differentiation for Expectation Values Read the paper ➔\nIntroduced a new mathematical foundation and language for automatic, efficient gradient estimation, critical for combining probabilistic software with gradient-based learning.\nGenJAX-VI — Programmable Variational Inference Read the paper ➔\nPresented a language with support for advanced variational inference algorithms, and never-used-before unbiased VI gradient estimators for probabilistic programs with discrete random variables.\n\n\n\n\nNeuroscience Research — Biologically Plausible Probabilistic Inference\n\nPrey Capture in Zebrafish Read the paper ➔\nBarrier Perception in Fish Read the paper ➔\n\nExperimental work showing how biological systems perform real-time probabilistic inference to guide perception and action."
  },
  {
    "objectID": "research/index.html#probabilistic-perception-and-3d-scene-understanding",
    "href": "research/index.html#probabilistic-perception-and-3d-scene-understanding",
    "title": "Papers",
    "section": "",
    "text": "Bayes3D — Uncertainty-Aware 3D Scene Perception with Novel Objects Read the paper ➔\nPresented an uncertainty-aware 3D scene perception system with GPU-accelerated pose tracking and novel object learning, capable of faster than real time 3D object tracking.\n3DP3 — 3D Scene Perception via Probabilistic Programming Read the paper ➔\nPresented 3D scene perception using inverse graphics — probabilistic inference in a structured generative model of objects, scenes, and images — the resulting algorithm produced representations aware of 3D shape, occlusion, and contact structure."
  },
  {
    "objectID": "research/index.html#inference-engineering-as-a-software-technology",
    "href": "research/index.html#inference-engineering-as-a-software-technology",
    "title": "Papers",
    "section": "",
    "text": "GenSP — Probabilistic Programming with Stochastic Probabilities Read the paper ➔\nPresented the first probabilistic programming language with expressive constructs like marginalization & nested inference, and features like continuous and discrete random variables, and programmable inference.\nGenSQL — PPL for Querying Probabilistic Database Models Read the paper ➔\nBy extending SQL with a few probabilistic primitives, presented a query language for generative models of database tables, illustrating how probabilistic tools can augment and extend conventional software systems."
  },
  {
    "objectID": "research/index.html#advances-in-gradient-estimation-and-inference-algorithms",
    "href": "research/index.html#advances-in-gradient-estimation-and-inference-algorithms",
    "title": "Papers",
    "section": "",
    "text": "ADEV — Automatic Differentiation for Expectation Values Read the paper ➔\nIntroduced a new mathematical foundation and language for automatic, efficient gradient estimation, critical for combining probabilistic software with gradient-based learning.\nGenJAX-VI — Programmable Variational Inference Read the paper ➔\nPresented a language with support for advanced variational inference algorithms, and never-used-before unbiased VI gradient estimators for probabilistic programs with discrete random variables."
  },
  {
    "objectID": "research/index.html#neuroscience-inspired-computation-and-active-perception",
    "href": "research/index.html#neuroscience-inspired-computation-and-active-perception",
    "title": "Papers",
    "section": "",
    "text": "Neuroscience Research — Biologically Plausible Probabilistic Inference\n\nPrey Capture in Zebrafish Read the paper ➔\nBarrier Perception in Fish Read the paper ➔\n\nExperimental work showing how biological systems perform real-time probabilistic inference to guide perception and action."
  },
  {
    "objectID": "research/index.html#visualization-driven-inference-development",
    "href": "research/index.html#visualization-driven-inference-development",
    "title": "Papers",
    "section": "Visualization-Driven Inference Development",
    "text": "Visualization-Driven Inference Development\nStudio — Visualization-driven development and debugging of inference GitHub ➔\nStudio supports modular visualization of probabilistic program traces and interactive debugging of probabilistic inference programs. Makes visual exploration and debugging convenient and fast."
  },
  {
    "objectID": "research/index.html#webgpu-and-lightweight-inference-deployment",
    "href": "research/index.html#webgpu-and-lightweight-inference-deployment",
    "title": "Papers",
    "section": "WebGPU and Lightweight Inference Deployment",
    "text": "WebGPU and Lightweight Inference Deployment\nRobot Localization via Studio — Active localization using live visualization\nDemoed real-time environment mapping and localization through interactive wall-drawing, recomputing paths dynamically based on user edits—showing the reflexive, real-time nature of probabilistic programs linked to visualization. Visualization with Studio."
  },
  {
    "objectID": "research/index.html#genjax-inference-engineering-with-gpu-accelerated-probabilistic-programs",
    "href": "research/index.html#genjax-inference-engineering-with-gpu-accelerated-probabilistic-programs",
    "title": "Papers",
    "section": "GenJAX: Inference Engineering with GPU-accelerated Probabilistic Programs",
    "text": "GenJAX: Inference Engineering with GPU-accelerated Probabilistic Programs\nInteractive ADEV Demo — Correct unbiased gradient estimation in noisy environments\nDemonstrated ADEV’s correctness under probability compared to conventional gradient descent, highlighting the advantage of probabilistic programming foundations when operating under uncertainty. Visualization with Studio."
  },
  {
    "objectID": "research/index.html#smcnn-sequential-monte-carlo-neural-networks",
    "href": "research/index.html#smcnn-sequential-monte-carlo-neural-networks",
    "title": "Papers",
    "section": "SMCNN — Sequential Monte Carlo Neural Networks",
    "text": "SMCNN — Sequential Monte Carlo Neural Networks\nBrain-inspired particle filtering for perception\nBuilt an interactive model where a probabilistic program tracks a moving target behind occlusions, executed on a model of neurons in a biologically plausible architecture. Showed dynamic inference, particle posterior visualization, and spiking activity aligned with cortical models. Visualization with Studio."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mission",
    "section": "",
    "text": "Mission\nOur mission is to accelerate the deployment of machines that can perceive, reason, and safely interact with the complexities of the physical world. We’re building modular AI components and a developer platform that enables companies to build, integrate and control physical AI without starting from scratch.\nPhysical AI deployments will revolutionize information processing systems in two ways:\n\nIntelligent machinery will act as a force multiplier for human operators looking to manipulate the physical world\nTargeted data feeds produced by this machinery will allow existing digital systems to plan and coordinate more effectively\n\nImagine automated construction equipment that can fill in detailed soil composition maps as a dig proceeds, or patient monitoring systems aware that they are participating in a hospital-wide optimization process.\nCurrent approaches treat physical AI as standalone automation rather than as extensions of digital infrastructure. The real opportunity lies in building physical AI with the explicit goal of participating in existing systems—not just automating isolated tasks, but serving as intelligent sensors that can execute specific functions while continuously reporting back both their intended outputs and the rich environmental data they gather as a byproduct.\n\n\n\nWhat we’re building\nToday’s physical AI deployments fail because teams approach core systems like vision, localization, and decision-making independently, using ad-hoc solutions that are often brittle and generalize poorly. The resulting systems behave unpredictably and can’t produce reliable data for ingestion into existing digital infrastructure.\nWe aim to solve this problem by building an AI platform for perception, reasoning and planning in physical systems. Our platform will provide domain specific AI modules operable via clean APIs and designed to integrate with existing software, models, agents, and commodity hardware. Our software runs on the GPU and handles the hard problems of sensor fusion and multi-input reasoning at the edge, so a users’ physical systems can participate intelligently as peripherals of a larger system instead of operating as unreliable, unpredictable pieces of machinery.\n\nOur goal is to do for physical AI what Cisco did for networking, or Stripe did for payment infrastructure.\n\nTo achieve this, we will build:\n\nBasic physical AI modules for machine perception and localization\nCoordination interfaces that combine these modules into reliable composite systems\nData interfaces for these modules, so that users can absorb valuable data back into their digital systems\nReliable “human override” abilities for all modules, so that humans can intervene and resolve ambiguity\nA developer platform to handle logging, monitoring, aggregation and reporting at the interface between physical AI and digital systems\n\n\n\n\nHow we’re starting\nWe bring deep expertise in probabilistic modeling and inference-time compute, and we’re translating that into real-world impact with obsessive focus on user problems and craftsmanship in every layer of the product.\nWe began by interviewing dozens of companies making bets on physical AI. Out of these, we’re partnering with a small number of companies in different verticals building information processing systems with an important physical AI component. We’ll work closely with each team to deploy their domain-specific physical automation, and to adapt their digital infrastructure to make effective use of the data generated by these intelligent systems.\nOur first set of modules enable reliable perception in the real world by:\n\nAccurately mapping the environment, along with the agent itself\nFusing multiple sensor streams intelligently (camera, LiDAR, radar, INS) in order to perceive robustly in difficult environments\nAbstracting matter into percepts / objects with semantic meaning (i.e. humans)\nData-efficiently recognizing and learning the features of novel objects\nRunning reliably on edge hardware with no network connection\n\n\n\n\nWhy Us?\nOur team combines deep expertise from both academia and industry.\nAt companies like Twitter, Stripe and Google [x], we’ve scaled production information systems to support billions of users, pioneered machine learning infrastructure at scale, and built developer platforms used by some of the world’s most sophisticated engineering organizations.\nThe explosion of neural net architectures and applications was built on a strong investment in compilers and programming languages (pytorch, tensorflow). Our team has similar PL and compiler expertise and is prepared to unlock a similar explosion for physical AI.\nThe techniques we’re using are in the same family as the “inference-time compute” methods that are delivering excellent results for coordinating neural nets. Our team has spent years at MIT perfecting our ability to explore this space.\n\n\n\nFocused on Users\nWe’d love to speak with you more to understand your challenges and see if an early partnership makes sense. If you’re working in any of the following areas, send us a note at hello@frogrocket.ai.\n\nRobotics for manufacturing, logistics, and inspection\nField systems for agriculture, exploration, and disaster recovery\nHome and assistive robotics\nDrones and autonomous vehicles\nAR/VR and wearable devices\nFrontier model developers needing better grounding in the physical world"
  }
]